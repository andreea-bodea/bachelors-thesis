{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa578a7d",
   "metadata": {},
   "source": [
    "## @misc{grootendorst2020bertopic,\n",
    "  author       = {Maarten Grootendorst},\n",
    "  title        = {BERTopic: Leveraging BERT and c-TF-IDF to create easily interpretable topics.},\n",
    "  year         = 2020,\n",
    "  publisher    = {Zenodo},\n",
    "  version      = {v0.9.4},\n",
    "  doi          = {10.5281/zenodo.4381785},\n",
    "  url          = {https://doi.org/10.5281/zenodo.4381785}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923d674d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BERTopic Maarten Grootendorst\n",
    "# Installation with sentence-transformers\n",
    "\n",
    "# pip install bertopic\n",
    "\n",
    "#    3 main algorithm components\n",
    "# 1. Embed Documents: Extract document embeddings with Sentence Transformers\n",
    "# 2. Cluster Documents: Create groups of similar documents with UMAP (to reduce the dimensionality of embeddings) \n",
    "#    and HDBSCAN (to identify and cluster semantically similar documents)\n",
    "# 3. Create Topic Representation: Extract and reduce topics with c-TF-IDF \n",
    "#    (class-based term frequency, inverse document frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f1a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting topics and generting probabilities\n",
    "\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    " \n",
    "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548959b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-22b5019ff26f>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-22b5019ff26f>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    >>> topic_model.get_topic_info()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# access the frequent topics that were generated\n",
    "# -1 refers to all outliers and should typically be ignored\n",
    "\n",
    ">>> topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequent topic that was generated, topic 0\n",
    "\n",
    ">>> topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd286ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Topics\n",
    "\n",
    "topic_model.visualize_topics()\n",
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Topic Modeling (DTM) is a collection of techniques aimed at analyzing the evolution of topics over time. \n",
    "# These methods allow you to understand how a topic is represented over time.\n",
    "# Here, we will be using all of Donald Trump's tweet to see how he talked over certain topics over time:\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "trump = pd.read_csv('https://drive.google.com/uc?export=download&id=1xRKHaP-QwACMydlDnyFPEaFdtskJuBa6')\n",
    "trump.text = trump.apply(lambda row: re.sub(r\"http\\S+\", \"\", row.text).lower(), 1)\n",
    "trump.text = trump.apply(lambda row: \" \".join(filter(lambda x:x[0]!=\"@\", row.text.split())), 1)\n",
    "trump.text = trump.apply(lambda row: \" \".join(re.sub(\"[^a-zA-Z]+\", \" \", row.text).split()), 1)\n",
    "trump = trump.loc[(trump.isRetweet == \"f\") & (trump.text != \"\"), :]\n",
    "timestamps = trump.date.to_list()\n",
    "tweets = trump.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e12ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the global topic representations by creating and training a BERTopic model\n",
    "\n",
    "topic_model = BERTopic(verbose=True)\n",
    "topics, probs = topic_model.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From these topics generate the topic representations at each timestamp for each topic\n",
    "# by calling topics_over_time and pass in his tweets, the corresponding timestamps, and the related topics\n",
    "\n",
    "topics_over_time = topic_model.topics_over_time(tweets, topics, timestamps, nr_bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics by calling visualize_topics_over_time()\n",
    "\n",
    "topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
