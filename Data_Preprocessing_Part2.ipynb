{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING Part 2\n",
    "\n",
    "8. Read CSV file containing only useful info (no index) as pandas dataframe\n",
    "9. Convert [body] of tweets to lowercase\n",
    "10. Remove emojis from [body] of tweets (demoji library)\n",
    "11. Remove English and Spanish stopwords from [body] of tweets (using stopwords from nltk corpus)\n",
    "12. Expand contractions from [body] of tweets (contractions library) (ex: you’re => you are) \n",
    "13. Remove punctuation from [body] of tweets (using string.punctuation)\n",
    "14. Remove numbers from [body] of tweets (re = regular expression library)\n",
    "15. Lemmatization of [body] of tweets (using WordNetLemmatizer from nltk) (ex: says => say) \n",
    "16. Remove words shorter than 3 characters from [body] of tweets\n",
    "17. Filter out null values found in [body] of tweets once more = dimension reduction (rows)\n",
    "18. Save pandas dataframe without index after preprocessing as CSV file\n",
    "19. Save pandas dataframes without index for each month after preprocessing as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     body createdAtformatted\n",
      "0        Professor my ass more like a pot head gone meth.         2020-12-13\n",
      "1                    Need To Spread The News, Jo Ann !!..         2020-12-10\n",
      "2               Fuck yes fire this loser non American !!!         2020-11-12\n",
      "3                                     Hang that pedophile         2020-12-25\n",
      "4       @Ivanka2020 You must be a sex and love the dep...         2020-12-08\n",
      "...                                                   ...                ...\n",
      "294636  This ugly alcoholic should just sit down at th...         2020-12-23\n",
      "294637                                              Boom!         2020-11-02\n",
      "294638  Exactly what I think every time I see John Rob...         2020-12-25\n",
      "294639                            Twat, the term is twat!         2020-11-18\n",
      "294640                                            Love it         2020-12-20\n",
      "\n",
      "[294641 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 8. Read CSV file containing only useful info (no index) as pandas dataframe\n",
    "\n",
    "parler_df = pd.read_csv('C:\\\\Users\\\\cosmi\\\\Desktop\\\\ANDREEA\\\\bachelors-thesis\\\\parler_df_030_dates_before.csv')\n",
    "print(parler_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Professor my ass more like a pot head gone meth.\n",
      "1                      Need To Spread The News, Jo Ann !!..\n",
      "2                 Fuck yes fire this loser non American !!!\n",
      "3                                       Hang that pedophile\n",
      "4         @Ivanka2020 You must be a sex and love the dep...\n",
      "                                ...                        \n",
      "294636    This ugly alcoholic should just sit down at th...\n",
      "294637                                                Boom!\n",
      "294638    Exactly what I think every time I see John Rob...\n",
      "294639                              Twat, the term is twat!\n",
      "294640                                              Love it\n",
      "Name: body, Length: 294641, dtype: object\n",
      "0          professor my ass more like a pot head gone meth.\n",
      "1                      need to spread the news, jo ann !!..\n",
      "2                 fuck yes fire this loser non american !!!\n",
      "3                                       hang that pedophile\n",
      "4         @ivanka2020 you must be a sex and love the dep...\n",
      "                                ...                        \n",
      "294636    this ugly alcoholic should just sit down at th...\n",
      "294637                                                boom!\n",
      "294638    exactly what i think every time i see john rob...\n",
      "294639                              twat, the term is twat!\n",
      "294640                                              love it\n",
      "Name: body, Length: 294641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 9. Convert [body] of tweets to lowercase\n",
    "\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([w.lower() for w in x.split()]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          professor my ass more like a pot head gone meth.\n",
      "1                      need to spread the news, jo ann !!..\n",
      "2                 fuck yes fire this loser non american !!!\n",
      "3                                       hang that pedophile\n",
      "4         @ivanka2020 you must be a sex and love the dep...\n",
      "                                ...                        \n",
      "294636    this ugly alcoholic should just sit down at th...\n",
      "294637                                                boom!\n",
      "294638    exactly what i think every time i see john rob...\n",
      "294639                              twat, the term is twat!\n",
      "294640                                              love it\n",
      "Name: body, Length: 294641, dtype: object\n",
      "0          professor my ass more like a pot head gone meth.\n",
      "1                      need to spread the news, jo ann !!..\n",
      "2                 fuck yes fire this loser non american !!!\n",
      "3                                       hang that pedophile\n",
      "4         @ivanka2020 you must be a sex and love the dep...\n",
      "                                ...                        \n",
      "294636    this ugly alcoholic should just sit down at th...\n",
      "294637                                                boom!\n",
      "294638    exactly what i think every time i see john rob...\n",
      "294639                              twat, the term is twat!\n",
      "294640                                              love it\n",
      "Name: body, Length: 294641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 10. Remove emojis from [body] of tweets (demoji library)\n",
    "\n",
    "import demoji\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: demoji.replace(x, \"\"))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          professor my ass more like a pot head gone meth.\n",
      "1                      need to spread the news, jo ann !!..\n",
      "2                 fuck yes fire this loser non american !!!\n",
      "3                                       hang that pedophile\n",
      "4         @ivanka2020 you must be a sex and love the dep...\n",
      "                                ...                        \n",
      "294636    this ugly alcoholic should just sit down at th...\n",
      "294637                                                boom!\n",
      "294638    exactly what i think every time i see john rob...\n",
      "294639                              twat, the term is twat!\n",
      "294640                                              love it\n",
      "Name: body, Length: 294641, dtype: object\n",
      "0                    professor ass like pot head gone meth.\n",
      "1                             need spread news, jo ann !!..\n",
      "2                      fuck yes fire loser non american !!!\n",
      "3                                            hang pedophile\n",
      "4         @ivanka2020 must sex love deprived human being...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guys ...\n",
      "294637                                                boom!\n",
      "294638    exactly think every time see john roberts smir...\n",
      "294639                                     twat, term twat!\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 11. Remove English and Spanish stopwords from [body] of tweets (using stopwords from nltk corpus)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "english_stop_words = [sw for sw in nltk.corpus.stopwords.words('english') if sw not in ['not', 'no']]\n",
    "english_stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "# print(english_stop_words)\n",
    "spanish_stop_words = stopwords.words('spanish')\n",
    "# print(spanish_stop_words)\n",
    "\n",
    "print(parler_df['body'])\n",
    "\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([w for w in x.split() if w not in english_stop_words]))\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([w for w in x.split() if w not in spanish_stop_words]))\n",
    "\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                    professor ass like pot head gone meth.\n",
      "1                             need spread news, jo ann !!..\n",
      "2                      fuck yes fire loser non american !!!\n",
      "3                                            hang pedophile\n",
      "4         @ivanka2020 must sex love deprived human being...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guys ...\n",
      "294637                                                boom!\n",
      "294638    exactly think every time see john roberts smir...\n",
      "294639                                     twat, term twat!\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n",
      "0                    professor ass like pot head gone meth.\n",
      "1                             need spread news, jo ann !!..\n",
      "2                      fuck yes fire loser non american !!!\n",
      "3                                            hang pedophile\n",
      "4         @ivanka2020 must sex love deprived human being...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guys ...\n",
      "294637                                                boom!\n",
      "294638    exactly think every time see john roberts smir...\n",
      "294639                                     twat, term twat!\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 12. Expand contractions from [body] of tweets (contractions library) (ex: you’re => you are) \n",
    "\n",
    "import contractions\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                    professor ass like pot head gone meth.\n",
      "1                             need spread news, jo ann !!..\n",
      "2                      fuck yes fire loser non american !!!\n",
      "3                                            hang pedophile\n",
      "4         @ivanka2020 must sex love deprived human being...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guys ...\n",
      "294637                                                boom!\n",
      "294638    exactly think every time see john roberts smir...\n",
      "294639                                     twat, term twat!\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n",
      "0                     professor ass like pot head gone meth\n",
      "1                                  need spread news jo ann \n",
      "2                         fuck yes fire loser non american \n",
      "3                                            hang pedophile\n",
      "4         ivanka2020 must sex love deprived human being ...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guys ...\n",
      "294637                                                 boom\n",
      "294638    exactly think every time see john roberts smir...\n",
      "294639                                       twat term twat\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 13. Remove punctuation from [body] of tweets (using string.punctuation)\n",
    "\n",
    "import string \n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ''.join([i for i in x if i not in string.punctuation]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     professor ass like pot head gone meth\n",
      "1                                  need spread news jo ann \n",
      "2                         fuck yes fire loser non american \n",
      "3                                            hang pedophile\n",
      "4         ivanka2020 must sex love deprived human being ...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guys ...\n",
      "294637                                                 boom\n",
      "294638    exactly think every time see john roberts smir...\n",
      "294639                                       twat term twat\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n",
      "0                     professor ass like pot head gone meth\n",
      "1                                   need spread news jo ann\n",
      "2                          fuck yes fire loser non american\n",
      "3                                            hang pedophile\n",
      "4         ivanka must sex love deprived human being ever...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guys ...\n",
      "294637                                                 boom\n",
      "294638    exactly think every time see john roberts smir...\n",
      "294639                                       twat term twat\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 14. Remove numbers from [body] of tweets (re = regular expression library)\n",
    "\n",
    "import re\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join(re.sub(\"[^a-zA-Z]+\", \" \", x).split()))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     professor ass like pot head gone meth\n",
      "1                                   need spread news jo ann\n",
      "2                          fuck yes fire loser non american\n",
      "3                                            hang pedophile\n",
      "4         ivanka must sex love deprived human being ever...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guys ...\n",
      "294637                                                 boom\n",
      "294638    exactly think every time see john roberts smir...\n",
      "294639                                       twat term twat\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n",
      "0                      professor as like pot head gone meth\n",
      "1                                   need spread news jo ann\n",
      "2                          fuck yes fire loser non american\n",
      "3                                            hang pedophile\n",
      "4         ivanka must sex love deprived human being ever...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guy t...\n",
      "294637                                                 boom\n",
      "294638    exactly think every time see john robert smirk...\n",
      "294639                                       twat term twat\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 15. Lemmatization of [body] of tweets (using WordNetLemmatizer from nltk) (ex: says => say) \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([WordNetLemmatizer().lemmatize(w) for w in x.split()]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      professor as like pot head gone meth\n",
      "1                                   need spread news jo ann\n",
      "2                          fuck yes fire loser non american\n",
      "3                                            hang pedophile\n",
      "4         ivanka must sex love deprived human being ever...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guy t...\n",
      "294637                                                 boom\n",
      "294638    exactly think every time see john robert smirk...\n",
      "294639                                       twat term twat\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n",
      "0                         professor like pot head gone meth\n",
      "1                                      need spread news ann\n",
      "2                          fuck yes fire loser non american\n",
      "3                                            hang pedophile\n",
      "4         ivanka must sex love deprived human being ever...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guy t...\n",
      "294637                                                 boom\n",
      "294638    exactly think every time see john robert smirk...\n",
      "294639                                       twat term twat\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 16. Remove words shorter than 3 characters from [body] of tweets\n",
    "\n",
    "print(parler_df['body'])\n",
    "parler_df['body'] = parler_df['body'].apply(lambda x: ' '.join([w.strip() for w in x.split() if len(w.strip()) >= 3]))\n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataframe: (294641, 2)\n",
      "0                         professor like pot head gone meth\n",
      "1                                      need spread news ann\n",
      "2                          fuck yes fire loser non american\n",
      "3                                            hang pedophile\n",
      "4         ivanka must sex love deprived human being ever...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guy t...\n",
      "294637                                                 boom\n",
      "294638    exactly think every time see john robert smirk...\n",
      "294639                                       twat term twat\n",
      "294640                                                 love\n",
      "Name: body, Length: 294641, dtype: object\n",
      "\n",
      "Dimension of dataframe after preprocessing: (286569, 2)\n",
      "0                         professor like pot head gone meth\n",
      "1                                      need spread news ann\n",
      "2                          fuck yes fire loser non american\n",
      "3                                            hang pedophile\n",
      "4         ivanka must sex love deprived human being ever...\n",
      "                                ...                        \n",
      "294636    ugly alcoholic sit bar keep picking last guy t...\n",
      "294637                                                 boom\n",
      "294638    exactly think every time see john robert smirk...\n",
      "294639                                       twat term twat\n",
      "294640                                                 love\n",
      "Name: body, Length: 286569, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 17. Filter out null values found in [body] of tweets once more = dimension reduction (rows)\n",
    "\n",
    "print('Dimension of dataframe: ' + str(parler_df.shape)) \n",
    "print(parler_df['body']) \n",
    "\n",
    "parler_df['body'].replace(\"\", np.nan, inplace=True)\n",
    "parler_df.dropna(subset=['body'], inplace=True)\n",
    "\n",
    "print('\\n'  + 'Dimension of dataframe after preprocessing: ' + str(parler_df.shape)) \n",
    "print(parler_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Save pandas dataframe without index after preprocessing as CSV file\n",
    "\n",
    "parler_df.to_csv('parler_df_030_dates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of whole dataframe after preprocessing: (286569, 3)\n",
      "                                                     body createdAtformatted  \\\n",
      "0                       professor like pot head gone meth         2020-12-13   \n",
      "1                                    need spread news ann         2020-12-10   \n",
      "2                        fuck yes fire loser non american         2020-11-12   \n",
      "3                                          hang pedophile         2020-12-25   \n",
      "4       ivanka must sex love deprived human being ever...         2020-12-08   \n",
      "...                                                   ...                ...   \n",
      "294636  ugly alcoholic sit bar keep picking last guy t...         2020-12-23   \n",
      "294637                                               boom         2020-11-02   \n",
      "294638  exactly think every time see john robert smirk...         2020-12-25   \n",
      "294639                                     twat term twat         2020-11-18   \n",
      "294640                                               love         2020-12-20   \n",
      "\n",
      "       month  \n",
      "0        dec  \n",
      "1        dec  \n",
      "2        nov  \n",
      "3        dec  \n",
      "4        dec  \n",
      "...      ...  \n",
      "294636   dec  \n",
      "294637   nov  \n",
      "294638   dec  \n",
      "294639   nov  \n",
      "294640   dec  \n",
      "\n",
      "[286569 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cosmi\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\cosmi\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\cosmi\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of November dataframe after preprocessing: (286569, 3)\n",
      "                                                     body createdAtformatted\n",
      "2                        fuck yes fire loser non american         2020-11-12\n",
      "5                                      redparty send info         2020-11-25\n",
      "7       jenelleeason better not tell commie trash frie...         2020-11-15\n",
      "8       metamorphys take blocking win closed minded he...         2020-11-07\n",
      "10              metroswift mama nazi whore that paid xbox         2020-11-24\n",
      "...                                                   ...                ...\n",
      "294629                      fredo fredo fredo broke heart         2020-11-13\n",
      "294632              today november still feel slow reason         2020-11-07\n",
      "294634                                      report parler         2020-11-21\n",
      "294637                                               boom         2020-11-02\n",
      "294639                                     twat term twat         2020-11-18\n",
      "\n",
      "[164948 rows x 2 columns]\n",
      "Dimension of December dataframe after preprocessing: (286569, 3)\n",
      "                                                     body createdAtformatted\n",
      "0                       professor like pot head gone meth         2020-12-13\n",
      "1                                    need spread news ann         2020-12-10\n",
      "3                                          hang pedophile         2020-12-25\n",
      "4       ivanka must sex love deprived human being ever...         2020-12-08\n",
      "6                                       cjsteeler disable         2020-12-18\n",
      "...                                                   ...                ...\n",
      "294630  think cheating democrat crazy judge idea messi...         2020-12-12\n",
      "294633  fauciisafraud arrestfauci fauciisatraitor figh...         2020-12-20\n",
      "294636  ugly alcoholic sit bar keep picking last guy t...         2020-12-23\n",
      "294638  exactly think every time see john robert smirk...         2020-12-25\n",
      "294640                                               love         2020-12-20\n",
      "\n",
      "[93916 rows x 2 columns]\n",
      "Dimension of January dataframe after preprocessing: (27705, 2)\n",
      "                                                     body createdAtformatted\n",
      "18                                             biden pedo         2021-01-07\n",
      "58      qanonsense know shock not need government look...         2021-01-02\n",
      "64                       sjwhunter fucked should have cap         2021-01-08\n",
      "81                        presidentbiden life bring pussy         2021-01-01\n",
      "83                                               snailman         2021-01-05\n",
      "...                                                   ...                ...\n",
      "294573         thelaststronghold antizionist business you         2021-01-02\n",
      "294610  dang moron notice picked older people alone ne...         2021-01-02\n",
      "294612                         watch want info whatstrump         2021-01-07\n",
      "294627                                  evil vile monster         2021-01-09\n",
      "294631                        remove treasonous snake den         2021-01-04\n",
      "\n",
      "[27705 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 19. Save pandas dataframes without index for each month after preprocessing as CSV file\n",
    "\n",
    "def check_month(date):\n",
    "    if (((date.split('-'))[0] == '2020') and ((date.split('-'))[1] == '11')):    # November 2020\n",
    "        return 'nov'\n",
    "    elif (((date.split('-'))[0] == '2020') and ((date.split('-'))[1] == '12')):  # December 2020\n",
    "        return 'dec'\n",
    "    else:\n",
    "        return 'jan' # January  2021\n",
    "       \n",
    "\n",
    "print('Dimension of whole dataframe after preprocessing: ' + str(parler_df.shape)) \n",
    "print(parler_df)\n",
    "\n",
    "parler_df['month'] = parler_df['createdAtformatted'].apply(check_month)\n",
    "\n",
    "parler_df_nov = parler_df[parler_df['month'] == 'nov']\n",
    "parler_df_nov.drop(['month'], inplace = True, axis = 1) \n",
    "print('Dimension of November dataframe after preprocessing: ' + str(parler_df.shape)) \n",
    "print(parler_df_nov)\n",
    "\n",
    "parler_df_dec = parler_df[parler_df['month'] == 'dec']\n",
    "parler_df_dec.drop(['month'], inplace = True, axis = 1)  \n",
    "print('Dimension of December dataframe after preprocessing: ' + str(parler_df.shape)) \n",
    "print(parler_df_dec)\n",
    "\n",
    "parler_df_jan = parler_df[parler_df['month'] == 'jan']  \n",
    "parler_df_jan.drop(['month'], inplace = True, axis = 1) \n",
    "print('Dimension of January dataframe after preprocessing: ' + str(parler_df_jan.shape)) \n",
    "print(parler_df_jan)\n",
    "\n",
    "parler_df_nov.to_csv('parler_df_030_dates_nov.csv', index=False)\n",
    "parler_df_dec.to_csv('parler_df_030_dates_dec.csv', index=False)\n",
    "parler_df_jan.to_csv('parler_df_030_dates_jan.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
