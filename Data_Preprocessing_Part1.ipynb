{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING Part 1\n",
    "\n",
    "1. Read NDJSON file as pandas dataframe\n",
    "2. Remove unuseful columns = dimension reduction (columns) -> only [body] and [createdAtformatted] left\n",
    "3. Filter out null values found in [body] of tweets = dimension reduction (rows)\n",
    "4. Filter out tweets not in relevant time period = dimension reduction (rows) -> only Nov 2020, Dec 2020 and Jan 2021 left\n",
    "5. Filter out [body] of tweets in languages except English = dimension reduction (rows)\n",
    "6. Remove unuseful time info from [createdAtformatted] column -> only date info left \n",
    "7. Save pandas dataframe containing only useful info (no index) as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read NDJSON file as pandas dataframe\n",
    "\n",
    "parler_df = pd.read_json('D:\\\\bachelors_thesis\\Datasets\\parler_data\\parler_data000000000030.ndjson', lines = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comments', 'body', 'bodywithurls', 'createdAt', 'createdAtformatted',\n",
      "       'creator', 'datatype', 'depth', 'depthRaw', 'followers', 'following',\n",
      "       'hashtags', 'id', 'lastseents', 'links', 'media', 'parent', 'posts',\n",
      "       'sensitive', 'upvotes', 'urls', 'username', 'verified', 'article',\n",
      "       'impressions', 'preview', 'reposts', 'state', 'shareLink', 'color',\n",
      "       'commentDepth', 'controversy', 'conversation', 'downvotes', 'post',\n",
      "       'replyingTo', 'score', 'isPrimary'],\n",
      "      dtype='object')\n",
      "Dimension of whole dataframe: (1097921, 38)\n",
      "\n",
      "Index(['body', 'createdAtformatted'], dtype='object')\n",
      "Dimension of dataframe after removing columns: (1097921, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Remove unuseful columns = dimension reduction (columns) -> only [body] and [createdAtformatted] left\n",
    "\n",
    "print(parler_df.columns)\n",
    "print('Dimension of whole dataframe: ' + str(parler_df.shape) + '\\n') # df.shape -> (rows, columns)\n",
    "\n",
    "# final_df_1 = pd.DataFrame()\n",
    "# final_df_1['body'] = df['body'].copy()\n",
    "# final_df_1['createdAtformatted'] = df['createdAtformatted'].copy()\n",
    "# parler_df.drop(parler_df.iloc[:, 2:38], inplace = True, axis = 1) # remove all columns between column index 2 to 38\n",
    "# parler_df.drop(['comments'], inplace = True, axis = 1)            # remove first column\n",
    "parler_df.drop(parler_df.iloc[:, 5:38], inplace = True, axis = 1)   # remove all columns between column index 5 to 38\n",
    "parler_df.drop(['comments'], inplace = True, axis = 1)              # remove column nr. 0\n",
    "parler_df.drop(['bodywithurls'], inplace = True, axis = 1)          # remove column nr. 2\n",
    "parler_df.drop(['createdAt'], inplace = True, axis = 1)             # remove column nr. 3\n",
    "\n",
    "print(parler_df.columns)\n",
    "print('Dimension of dataframe after removing columns: ' + str(parler_df.shape) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataframe: (1097921, 2)\n",
      "        body       createdAtformatted\n",
      "0             2019-10-14 00:26:36 UTC\n",
      "1             2020-07-30 12:02:25 UTC\n",
      "2             2020-11-09 04:22:41 UTC\n",
      "3             2020-07-05 06:36:11 UTC\n",
      "4             2020-11-23 13:25:53 UTC\n",
      "...      ...                      ...\n",
      "1097916       2021-01-05 17:31:36 UTC\n",
      "1097917       2020-01-21 12:41:41 UTC\n",
      "1097918       2020-06-05 03:48:34 UTC\n",
      "1097919       2019-11-02 14:07:03 UTC\n",
      "1097920       2020-11-20 05:16:40 UTC\n",
      "\n",
      "[1097921 rows x 2 columns]\n",
      "\n",
      "Dimension of dataframe after filtering out null values: (638636, 2)\n",
      "                                                      body  \\\n",
      "33       I agree, get the US outa UN, and convert that ...   \n",
      "79        Professor my ass more like a pot head gone meth.   \n",
      "134      Expand the electoral college so that large cit...   \n",
      "170                   Need To Spread The News, Jo Ann !!..   \n",
      "346                                          Demon Spawn..   \n",
      "...                                                    ...   \n",
      "1097851  What NASCAR?\\nWhat NFL?\\nWhat NBA?\\nWhat MLB?\\...   \n",
      "1097877                                         She’s good   \n",
      "1097897  The DEMONRATS/DEMOCRATS/SOCIALIST Pigs Cheated...   \n",
      "1097901                                            Love it   \n",
      "1097910  THEY COMMITTED TREASON!!!!!!!\\n\\nTHEY MUST AND...   \n",
      "\n",
      "              createdAtformatted  \n",
      "33       2020-08-22 19:18:42 UTC  \n",
      "79       2020-12-13 13:43:28 UTC  \n",
      "134      2019-12-16 01:39:41 UTC  \n",
      "170      2020-12-10 18:39:32 UTC  \n",
      "346      2020-10-13 22:19:41 UTC  \n",
      "...                          ...  \n",
      "1097851  2020-07-07 23:22:32 UTC  \n",
      "1097877  2019-11-15 23:58:48 UTC  \n",
      "1097897  2021-01-03 11:27:27 UTC  \n",
      "1097901  2020-12-20 22:22:55 UTC  \n",
      "1097910  2020-12-31 23:16:51 UTC  \n",
      "\n",
      "[638636 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3. Filter out null values found in [body] of tweets = dimension reduction (rows)\n",
    "\n",
    "print('Dimension of dataframe: ' + str(parler_df.shape)) \n",
    "print(parler_df) \n",
    "\n",
    "parler_df['body'].replace(\"\", np.nan, inplace=True)\n",
    "parler_df.dropna(subset=['body'], inplace=True)\n",
    "# parler_df.reset_index(drop=True, inplace=True)\n",
    "# parler_df.drop_duplicates(subset = ['body'], inplace=True, keep='first'/'last'/False)\n",
    "\n",
    "print('\\n'  + 'Dimension of dataframe after filtering out null values: ' + str(parler_df.shape)) \n",
    "print(parler_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataframe before: (638636, 2)\n",
      "                                                      body  \\\n",
      "33       I agree, get the US outa UN, and convert that ...   \n",
      "79        Professor my ass more like a pot head gone meth.   \n",
      "134      Expand the electoral college so that large cit...   \n",
      "170                   Need To Spread The News, Jo Ann !!..   \n",
      "346                                          Demon Spawn..   \n",
      "...                                                    ...   \n",
      "1097851  What NASCAR?\\nWhat NFL?\\nWhat NBA?\\nWhat MLB?\\...   \n",
      "1097877                                         She’s good   \n",
      "1097897  The DEMONRATS/DEMOCRATS/SOCIALIST Pigs Cheated...   \n",
      "1097901                                            Love it   \n",
      "1097910  THEY COMMITTED TREASON!!!!!!!\\n\\nTHEY MUST AND...   \n",
      "\n",
      "              createdAtformatted  \n",
      "33       2020-08-22 19:18:42 UTC  \n",
      "79       2020-12-13 13:43:28 UTC  \n",
      "134      2019-12-16 01:39:41 UTC  \n",
      "170      2020-12-10 18:39:32 UTC  \n",
      "346      2020-10-13 22:19:41 UTC  \n",
      "...                          ...  \n",
      "1097851  2020-07-07 23:22:32 UTC  \n",
      "1097877  2019-11-15 23:58:48 UTC  \n",
      "1097897  2021-01-03 11:27:27 UTC  \n",
      "1097901  2020-12-20 22:22:55 UTC  \n",
      "1097910  2020-12-31 23:16:51 UTC  \n",
      "\n",
      "[638636 rows x 2 columns]\n",
      "Dimension of dataframe with tweets from relevant time period only: (353660, 2)\n",
      "                                                      body  \\\n",
      "79        Professor my ass more like a pot head gone meth.   \n",
      "170                   Need To Spread The News, Jo Ann !!..   \n",
      "362              Fuck yes fire this loser non American !!!   \n",
      "409                      EVERYONE PLEASE\\nECHO, ECHO, ECHO   \n",
      "491                                    Hang that pedophile   \n",
      "...                                                    ...   \n",
      "1097616  Exactly what I think every time I see John Rob...   \n",
      "1097656                            Twat, the term is twat!   \n",
      "1097897  The DEMONRATS/DEMOCRATS/SOCIALIST Pigs Cheated...   \n",
      "1097901                                            Love it   \n",
      "1097910  THEY COMMITTED TREASON!!!!!!!\\n\\nTHEY MUST AND...   \n",
      "\n",
      "              createdAtformatted  \n",
      "79       2020-12-13 13:43:28 UTC  \n",
      "170      2020-12-10 18:39:32 UTC  \n",
      "362      2020-11-12 02:09:25 UTC  \n",
      "409      2020-11-27 01:43:23 UTC  \n",
      "491      2020-12-25 01:18:19 UTC  \n",
      "...                          ...  \n",
      "1097616  2020-12-25 12:00:49 UTC  \n",
      "1097656  2020-11-18 17:42:38 UTC  \n",
      "1097897  2021-01-03 11:27:27 UTC  \n",
      "1097901  2020-12-20 22:22:55 UTC  \n",
      "1097910  2020-12-31 23:16:51 UTC  \n",
      "\n",
      "[353660 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter out tweets not in relevant time period = dimension reduction (rows) -> only Nov 2020, Dec 2020 and Jan 2021 left\n",
    "\n",
    "def check_date(string):\n",
    "    if ( (((string.split('-'))[0] == '2020') and ((string.split('-'))[1] == '11'))          # November 2020\n",
    "        or (((string.split('-'))[0] == '2020') and ((string.split('-'))[1] == '12'))        # December 2020\n",
    "        or (((string.split('-'))[0] == '2021') and ((string.split('-'))[1] == '01')) ):     # January  2021\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "print('Dimension of dataframe before: ' + str(parler_df.shape)) \n",
    "print(parler_df)\n",
    "\n",
    "parler_df['appropiateDate'] = parler_df['createdAtformatted'].apply(check_date)\n",
    "# parler_df.drop(parler_df[parler_df['appropiateDate'] == False].index, inplace=True)\n",
    "parler_df = parler_df[parler_df['appropiateDate'] == True]\n",
    "parler_df.drop(['appropiateDate'], inplace = True, axis = 1)          \n",
    "\n",
    "print('Dimension of dataframe with tweets from relevant time period only: ' + str(parler_df.shape)) \n",
    "print(parler_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataframe before: (353660, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of dataframe with tweets in English only: (353660, 3)\n",
      "                                                      body  \\\n",
      "79        Professor my ass more like a pot head gone meth.   \n",
      "170                   Need To Spread The News, Jo Ann !!..   \n",
      "362              Fuck yes fire this loser non American !!!   \n",
      "409                      EVERYONE PLEASE\\nECHO, ECHO, ECHO   \n",
      "491                                    Hang that pedophile   \n",
      "...                                                    ...   \n",
      "1097616  Exactly what I think every time I see John Rob...   \n",
      "1097656                            Twat, the term is twat!   \n",
      "1097897  The DEMONRATS/DEMOCRATS/SOCIALIST Pigs Cheated...   \n",
      "1097901                                            Love it   \n",
      "1097910  THEY COMMITTED TREASON!!!!!!!\\n\\nTHEY MUST AND...   \n",
      "\n",
      "              createdAtformatted language  \n",
      "79       2020-12-13 13:43:28 UTC       en  \n",
      "170      2020-12-10 18:39:32 UTC       en  \n",
      "362      2020-11-12 02:09:25 UTC       en  \n",
      "409      2020-11-27 01:43:23 UTC     None  \n",
      "491      2020-12-25 01:18:19 UTC       en  \n",
      "...                          ...      ...  \n",
      "1097616  2020-12-25 12:00:49 UTC       en  \n",
      "1097656  2020-11-18 17:42:38 UTC       en  \n",
      "1097897  2021-01-03 11:27:27 UTC     None  \n",
      "1097901  2020-12-20 22:22:55 UTC       en  \n",
      "1097910  2020-12-31 23:16:51 UTC     None  \n",
      "\n",
      "[353660 rows x 3 columns]\n",
      "                                                      body  \\\n",
      "79        Professor my ass more like a pot head gone meth.   \n",
      "170                   Need To Spread The News, Jo Ann !!..   \n",
      "362              Fuck yes fire this loser non American !!!   \n",
      "491                                    Hang that pedophile   \n",
      "648      @Ivanka2020 You must be a sex and love the dep...   \n",
      "...                                                    ...   \n",
      "1097610  This ugly alcoholic should just sit down at th...   \n",
      "1097613                                              Boom!   \n",
      "1097616  Exactly what I think every time I see John Rob...   \n",
      "1097656                            Twat, the term is twat!   \n",
      "1097901                                            Love it   \n",
      "\n",
      "              createdAtformatted  \n",
      "79       2020-12-13 13:43:28 UTC  \n",
      "170      2020-12-10 18:39:32 UTC  \n",
      "362      2020-11-12 02:09:25 UTC  \n",
      "491      2020-12-25 01:18:19 UTC  \n",
      "648      2020-12-08 23:16:48 UTC  \n",
      "...                          ...  \n",
      "1097610  2020-12-23 01:11:04 UTC  \n",
      "1097613  2020-11-02 13:24:42 UTC  \n",
      "1097616  2020-12-25 12:00:49 UTC  \n",
      "1097656  2020-11-18 17:42:38 UTC  \n",
      "1097901  2020-12-20 22:22:55 UTC  \n",
      "\n",
      "[294641 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 5. Filter out [body] of tweets in languages except English = dimension reduction (rows)\n",
    "\n",
    "import fasttext\n",
    "model = fasttext.load_model(\"lid.176.ftz\")\n",
    "\n",
    "def fast_detect(msg):\n",
    "    try:\n",
    "        ln = model.predict(msg)[0][0].split(\"__\")[2] \n",
    "    except Exception as e:\n",
    "        ln = None\n",
    "    return ln\n",
    "\n",
    "print('Dimension of dataframe before: ' + str(parler_df.shape)) \n",
    "parler_df['language'] = parler_df['body'].apply(fast_detect)\n",
    "print('Dimension of dataframe with tweets in English only: ' + str(parler_df.shape)) \n",
    "\n",
    "print(parler_df)\n",
    "parler_df.drop(parler_df[parler_df['language'] != 'en'].index, inplace=True)\n",
    "parler_df.drop(['language'], inplace = True, axis = 1)          \n",
    "print(parler_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79         2020-12-13 13:43:28 UTC\n",
      "170        2020-12-10 18:39:32 UTC\n",
      "362        2020-11-12 02:09:25 UTC\n",
      "491        2020-12-25 01:18:19 UTC\n",
      "648        2020-12-08 23:16:48 UTC\n",
      "                    ...           \n",
      "1097610    2020-12-23 01:11:04 UTC\n",
      "1097613    2020-11-02 13:24:42 UTC\n",
      "1097616    2020-12-25 12:00:49 UTC\n",
      "1097656    2020-11-18 17:42:38 UTC\n",
      "1097901    2020-12-20 22:22:55 UTC\n",
      "Name: createdAtformatted, Length: 294641, dtype: object\n",
      "79         2020-12-13\n",
      "170        2020-12-10\n",
      "362        2020-11-12\n",
      "491        2020-12-25\n",
      "648        2020-12-08\n",
      "              ...    \n",
      "1097610    2020-12-23\n",
      "1097613    2020-11-02\n",
      "1097616    2020-12-25\n",
      "1097656    2020-11-18\n",
      "1097901    2020-12-20\n",
      "Name: createdAtformatted, Length: 294641, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 6. Remove unuseful time info from [createdAtformatted] column -> only date info left \n",
    "\n",
    "print(parler_df['createdAtformatted'])\n",
    "parler_df['createdAtformatted'] = parler_df['createdAtformatted'].str.split(n = 0, expand = False).str[0]\n",
    "print(parler_df['createdAtformatted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save pandas dataframe containing only useful info (no index) as CSV file\n",
    "\n",
    "parler_df.to_csv('parler_df_030_dates_before.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
